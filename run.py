#!/usr/bin/env python3
"""
é›ªçƒè‚¡ç¥¨æ•°æ®çˆ¬è™«
ä¸»è¦åŠŸèƒ½ï¼š
Step 1: æµ‹è¯•è®¤è¯çŠ¶æ€
    è‹¥è®¤è¯çŠ¶æ€å¼‚å¸¸ï¼Œæç¤ºå…ˆè·å–é›ªçƒCookieï¼Œè¿è¡Œget_cookie.py
    è‹¥è®¤è¯çŠ¶æ€æ­£å¸¸ï¼Œè¿›å…¥Step 2
Step 2: æ ¹æ®é€‰é¡¹çˆ¬å–æŒ‡å®šæ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°æ•°æ®åº“
    é€‰é¡¹å¦‚ä¸‹ï¼š
    1. çˆ¬å–å…¬å¸ä¿¡æ¯
    2. çˆ¬å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    3. çˆ¬å–Kçº¿æ•°æ®ï¼ˆæŒ‰æ—¥æœŸå­˜å‚¨ï¼‰
    4. çˆ¬å–è´¢åŠ¡æ•°æ®ï¼ˆæŒ‰è¯åˆ¸ä»£ç å­˜å‚¨ï¼‰
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crawlers.stock_info_crawler import StockInfoCrawler
from crawlers.kline_crawler import KlineCrawler
from crawlers.company_info_crawler import CompanyInfoCrawler
from crawlers.financial_crawler import FinancialCrawler
from engine.database import DataRepository
from engine.xueqiu_auth import get_auth

def test_authentication():
    """æµ‹è¯•è®¤è¯çŠ¶æ€"""
    print("\nğŸ” æµ‹è¯•è®¤è¯çŠ¶æ€...")
    print("-" * 30)
    
    auth = get_auth()
    cookies = auth.get_cookies()
    
    if not cookies:
        print("âŒ è®¤è¯çŠ¶æ€å¼‚å¸¸ï¼šæœªæ‰¾åˆ°Cookie")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
        print("è¯·å…ˆè·å–é›ªçƒCookieï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
        print("   python engine/get_cookie.py")
        print("\nğŸ“– è·å–Cookieå¼•å¯¼ï¼š")
        print("   1. æµè§ˆå™¨ç™»å½•é›ªçƒï¼šhttps://xueqiu.com")
        print("   2. F12 â†’ Network â†’ å¤åˆ¶Cookieå­—ç¬¦ä¸²")
        print("   3. ç²˜è´´åˆ° cookie_input.txt æ–‡ä»¶")
        print("   4. é‡æ–°è¿è¡Œ get_cookie.py")
        return False
    
    # æ£€æŸ¥ç”¨æˆ·ID
    user_id = cookies.get('u', '0')
    if user_id == '0':
        print("âš ï¸  è®¤è¯çŠ¶æ€å¼‚å¸¸ï¼šæ¸¸å®¢æ¨¡å¼ï¼ˆu=0ï¼‰")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
        print("è¯·ä½¿ç”¨ç™»å½•åçš„Cookieï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°è·å–ï¼š")
        print("   python engine/get_cookie.py")
        return False
    
    print(f"âœ… è®¤è¯çŠ¶æ€æ­£å¸¸ï¼šç”¨æˆ·ID {user_id}")
    
    # éªŒè¯Cookieæœ‰æ•ˆæ€§
    if auth._validate_cookies(cookies):
        print("âœ… CookieéªŒè¯é€šè¿‡")
        return True
    else:
        print("âš ï¸  CookieéªŒè¯å¤±è´¥")
        print("ğŸ’¡ å»ºè®®é‡æ–°è·å–Cookieï¼špython engine/get_cookie.py")
        return False


def show_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("\n" + "="*50)
    print("ğŸš€ é›ªçƒè‚¡ç¥¨æ•°æ®çˆ¬è™«")
    print("="*50)
    print("1. çˆ¬å–å…¬å¸ä¿¡æ¯ï¼ˆä¸å¿…éœ€ï¼‰")
    print("2. è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆå®Œæ•´å­—æ®µï¼‰")
    print("3. åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨ï¼ˆç®€åŒ–å­—æ®µï¼Œä¸å¿…éœ€ï¼‰")
    print("4. çˆ¬å–æ—¥é¢‘Kçº¿æ•°æ®ï¼ˆæŒ‰æ—¥æœŸå­˜å‚¨ï¼‰")
    print("5. çˆ¬å–è´¢åŠ¡æ•°æ®ï¼ˆæŒ‰è¯åˆ¸ä»£ç å­˜å‚¨ï¼‰")
    print("6. çˆ¬å–æ‰€æœ‰æ•°æ®")
    print("0. é€€å‡º")
    print("="*50)

def crawl_company_info():
    """çˆ¬å–å…¬å¸ä¿¡æ¯"""
    print("\nğŸ¢ å…¬å¸ä¿¡æ¯çˆ¬å–é€‰é¡¹")
    print("=" * 40)
    print("1. çˆ¬å–æ‰€æœ‰å…¬å¸ä¿¡æ¯")
    print("2. æŒ‰è¯åˆ¸ä»£ç çˆ¬å–å•ä¸ªå…¬å¸ä¿¡æ¯")
    print("3. æ‰¹é‡çˆ¬å–æŒ‡å®šå…¬å¸ä¿¡æ¯")
    print("4. æŸ¥çœ‹æŒ‡å®šå…¬å¸ä¿¡æ¯")
    print("5. æ›´æ–°æŒ‡å®šå…¬å¸ä¿¡æ¯")
    print("6. å¯¼å‡ºå…¬å¸ä¿¡æ¯åˆ°CSV")
    print("0. è¿”å›ä¸»èœå•")
    
    choice = input("\nè¯·é€‰æ‹© (0-6): ").strip()
    
    if choice == '0':
        return
    elif choice == '1':
        print("\nğŸ¢ å¼€å§‹çˆ¬å–æ‰€æœ‰å…¬å¸ä¿¡æ¯...")
        crawler = CompanyInfoCrawler(DataRepository())
        result = crawler.crawl_company_info()
        print(f"âœ… å…¬å¸ä¿¡æ¯çˆ¬å–å®Œæˆï¼æˆåŠŸ: {result['success']}, å¤±è´¥: {result['error']}")
    elif choice == '2':
        symbol = input("è¯·è¾“å…¥è¯åˆ¸ä»£ç  (å¦‚ SZ000001): ").strip()
        if symbol:
            print(f"\nğŸ¢ å¼€å§‹çˆ¬å–å…¬å¸ä¿¡æ¯: {symbol}")
            crawler = CompanyInfoCrawler(DataRepository())
            result = crawler.crawl_company_info_by_code(symbol)
            if result:
                print(f"âœ… å…¬å¸ä¿¡æ¯çˆ¬å–æˆåŠŸ: {symbol} - {result.get('compsname', '')}")
            else:
                print(f"âŒ å…¬å¸ä¿¡æ¯çˆ¬å–å¤±è´¥: {symbol}")
        else:
            print("âŒ è¯åˆ¸ä»£ç ä¸èƒ½ä¸ºç©º")
    elif choice == '3':
        symbols_input = input("è¯·è¾“å…¥è¯åˆ¸ä»£ç åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”ï¼Œå¦‚ SZ000001,SH600001): ").strip()
        if symbols_input:
            symbols = [s.strip() for s in symbols_input.split(',') if s.strip()]
            print(f"\nğŸ¢ å¼€å§‹æ‰¹é‡çˆ¬å–å…¬å¸ä¿¡æ¯ï¼Œå…±{len(symbols)}æ”¯è‚¡ç¥¨...")
            crawler = CompanyInfoCrawler(DataRepository())
            result = crawler.crawl_company_info_batch(symbols)
            print(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆï¼æˆåŠŸ: {result['success']}, å¤±è´¥: {result['error']}")
        else:
            print("âŒ è¯åˆ¸ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    elif choice == '4':
        symbol = input("è¯·è¾“å…¥è¯åˆ¸ä»£ç  (å¦‚ SZ000001): ").strip()
        if symbol:
            print(f"\nğŸ” æŸ¥è¯¢å…¬å¸ä¿¡æ¯: {symbol}")
            crawler = CompanyInfoCrawler(DataRepository())
            info = crawler.get_company_info_by_symbol(symbol)
            if info:
                print(f"âœ… æ‰¾åˆ°å…¬å¸ä¿¡æ¯:")
                print(f"   è¯åˆ¸ä»£ç : {info.get('compcode', '')}")
                print(f"   å…¬å¸åç§°: {info.get('compsname', '')}")
                print(f"   æ³•å®šåç§°: {info.get('compname', '')}")
                print(f"   è‹±æ–‡åç§°: {info.get('engname', '')}")
                print(f"   æˆç«‹æ—¶é—´: {info.get('founddate', '')}")
                print(f"   æ³¨å†Œèµ„æœ¬: {info.get('regcapital', '')}")
                print(f"   è‘£äº‹é•¿: {info.get('chairman', '')}")
                print(f"   æ€»ç»ç†: {info.get('manager', '')}")
                print(f"   æ³¨å†Œåœ°å€: {info.get('regaddr', '')}")
                print(f"   åŠå…¬åœ°å€: {info.get('officeaddr', '')}")
                print(f"   æ›´æ–°æ—¶é—´: {info.get('updated_at', '')}")
            else:
                print(f"âŒ æœªæ‰¾åˆ°å…¬å¸ä¿¡æ¯: {symbol}")
        else:
            print("âŒ è¯åˆ¸ä»£ç ä¸èƒ½ä¸ºç©º")
    elif choice == '5':
        symbol = input("è¯·è¾“å…¥è¯åˆ¸ä»£ç  (å¦‚ SZ000001): ").strip()
        if symbol:
            print(f"\nğŸ”„ æ›´æ–°å…¬å¸ä¿¡æ¯: {symbol}")
            crawler = CompanyInfoCrawler(DataRepository())
            result = crawler.update_company_info_by_symbol(symbol)
            if result:
                print(f"âœ… å…¬å¸ä¿¡æ¯æ›´æ–°æˆåŠŸ: {symbol} - {result.get('compsname', '')}")
            else:
                print(f"âŒ å…¬å¸ä¿¡æ¯æ›´æ–°å¤±è´¥: {symbol}")
        else:
            print("âŒ è¯åˆ¸ä»£ç ä¸èƒ½ä¸ºç©º")
    elif choice == '6':
        print("\nğŸ“„ å¯¼å‡ºå…¬å¸ä¿¡æ¯é€‰é¡¹")
        print("1. å¯¼å‡ºæ‰€æœ‰å…¬å¸ä¿¡æ¯")
        print("2. å¯¼å‡ºæŒ‡å®šå…¬å¸ä¿¡æ¯")
        export_choice = input("è¯·é€‰æ‹© (1-2): ").strip()
        
        if export_choice == '1':
            print("\nğŸ“„ å¯¼å‡ºæ‰€æœ‰å…¬å¸ä¿¡æ¯...")
            crawler = CompanyInfoCrawler(DataRepository())
            success = crawler.export_company_info_to_csv()
            if success:
                print("âœ… æ‰€æœ‰å…¬å¸ä¿¡æ¯å¯¼å‡ºæˆåŠŸï¼")
            else:
                print("âŒ å…¬å¸ä¿¡æ¯å¯¼å‡ºå¤±è´¥ï¼")
        elif export_choice == '2':
            symbols_input = input("è¯·è¾“å…¥è¯åˆ¸ä»£ç åˆ—è¡¨ (ç”¨é€—å·åˆ†éš”): ").strip()
            if symbols_input:
                symbols = [s.strip() for s in symbols_input.split(',') if s.strip()]
                print(f"\nğŸ“„ å¯¼å‡ºæŒ‡å®šå…¬å¸ä¿¡æ¯ï¼Œå…±{len(symbols)}æ”¯è‚¡ç¥¨...")
                crawler = CompanyInfoCrawler(DataRepository())
                success = crawler.export_company_info_to_csv(symbols=symbols)
                if success:
                    print("âœ… æŒ‡å®šå…¬å¸ä¿¡æ¯å¯¼å‡ºæˆåŠŸï¼")
                else:
                    print("âŒ å…¬å¸ä¿¡æ¯å¯¼å‡ºå¤±è´¥ï¼")
            else:
                print("âŒ è¯åˆ¸ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def get_stock_info():
    """è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆå®Œæ•´å­—æ®µï¼Œä¿å­˜åˆ°stock_infoï¼‰"""
    print("\nğŸ“ˆ è·å–è‚¡ç¥¨ä¿¡æ¯é€‰é¡¹")
    print("=" * 40)
    print("1. è·å–ä»Šæ—¥è‚¡ç¥¨ä¿¡æ¯")
    print("2. è·å–æŒ‡å®šæ—¥æœŸè‚¡ç¥¨ä¿¡æ¯")
    print("3. æŸ¥çœ‹æŒ‡å®šæ—¥æœŸè‚¡ç¥¨ä¿¡æ¯")
    print("0. è¿”å›ä¸»èœå•")
    
    choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()
    
    if choice == '0':
        return
    elif choice == '1':
        print("\nğŸ“ˆ å¼€å§‹è·å–ä»Šæ—¥è‚¡ç¥¨ä¿¡æ¯...")
        crawler = StockInfoCrawler(DataRepository())
        crawler.crawl_stock_list()
        print("âœ… ä»Šæ—¥è‚¡ç¥¨ä¿¡æ¯è·å–å®Œæˆï¼")
    elif choice == '2':
        date_str = input("è¯·è¾“å…¥æ—¥æœŸ (YYYY-MM-DDï¼Œå¦‚ 2024-01-01): ").strip()
        if date_str:
            print(f"\nğŸ“ˆ å¼€å§‹è·å– {date_str} çš„è‚¡ç¥¨ä¿¡æ¯...")
            # æ³¨æ„ï¼šå½“å‰stock_info_crawleråªæ”¯æŒè·å–å½“å¤©æ•°æ®
            # è¿™é‡Œå¯ä»¥æç¤ºç”¨æˆ·æˆ–ä¿®æ”¹çˆ¬è™«ä»¥æ”¯æŒæŒ‡å®šæ—¥æœŸ
            print("âš ï¸  æ³¨æ„ï¼šå½“å‰ç‰ˆæœ¬åªæ”¯æŒè·å–å½“å¤©æ•°æ®")
            crawler = StockInfoCrawler(DataRepository())
            crawler.crawl_stock_list()
            print("âœ… è‚¡ç¥¨ä¿¡æ¯è·å–å®Œæˆï¼")
        else:
            print("âŒ æ—¥æœŸä¸èƒ½ä¸ºç©º")
    elif choice == '3':
        date_str = input("è¯·è¾“å…¥æ—¥æœŸ (YYYY-MM-DDï¼Œç•™ç©ºä¸ºä»Šå¤©): ").strip()
        if not date_str:
            date_str = None
        print(f"\nğŸ” æŸ¥çœ‹è‚¡ç¥¨ä¿¡æ¯ï¼Œæ—¥æœŸ: {date_str or 'ä»Šå¤©'}")
        crawler = StockInfoCrawler(DataRepository())
        if hasattr(crawler.data_repo, 'csv_storage') and crawler.data_repo.csv_storage:
            stocks = crawler.data_repo.csv_storage.get_stock_info_by_date(date_str or '2025-11-22')
            if stocks:
                print(f"âœ… æ‰¾åˆ° {len(stocks)} æ¡è‚¡ç¥¨è®°å½•")
                print("\nå‰10æ¡è®°å½•:")
                print("-" * 80)
                for i, stock in enumerate(stocks[:10], 1):
                    print(f"{i:2d}. {stock.get('symbol', ''):<10} {stock.get('name', ''):<15} "
                          f"ä»·æ ¼:{stock.get('current', 0):>8.2f} "
                          f"æ¶¨è·Œ:{stock.get('percent', 0):>6.2f}% "
                          f"æˆäº¤é‡:{stock.get('volume', 0):>10,}")
                if len(stocks) > 10:
                    print(f"... è¿˜æœ‰ {len(stocks) - 10} æ¡è®°å½•")
            else:
                print(f"âŒ æœªæ‰¾åˆ° {date_str or 'ä»Šå¤©'} çš„è‚¡ç¥¨ä¿¡æ¯")
        else:
            print("âŒ å½“å‰ä¸æ”¯æŒæ•°æ®åº“æ¨¡å¼æŸ¥çœ‹")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def create_stock_list():
    """åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨ï¼ˆç®€åŒ–å­—æ®µï¼Œä¿å­˜åˆ°stock_listï¼‰"""
    print("\nğŸ“‹ åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨é€‰é¡¹")
    print("=" * 40)
    print("1. ä»ä»Šæ—¥stock_infoåˆ›å»ºç®€åŒ–åˆ—è¡¨")
    print("2. ä»æŒ‡å®šæ—¥æœŸstock_infoåˆ›å»ºç®€åŒ–åˆ—è¡¨")
    print("3. æŸ¥çœ‹æŒ‡å®šæ—¥æœŸè‚¡ç¥¨åˆ—è¡¨")
    print("0. è¿”å›ä¸»èœå•")
    
    choice = input("\nè¯·é€‰æ‹© (0-3): ").strip()
    
    if choice == '0':
        return
    elif choice == '1':
        print("\nğŸ“‹ ä»ä»Šæ—¥stock_infoåˆ›å»ºç®€åŒ–è‚¡ç¥¨åˆ—è¡¨...")
        crawler = StockInfoCrawler(DataRepository())
        result = crawler.create_simplified_stock_list()
        if result:
            print("âœ… ä»Šæ—¥ç®€åŒ–è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå®Œæˆï¼")
        else:
            print("âŒ ä»Šæ—¥ç®€åŒ–è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå¤±è´¥ï¼")
    elif choice == '2':
        date_str = input("è¯·è¾“å…¥æ—¥æœŸ (YYYY-MM-DDï¼Œå¦‚ 2024-01-01): ").strip()
        if date_str:
            print(f"\nğŸ“‹ ä» {date_str} çš„stock_infoåˆ›å»ºç®€åŒ–è‚¡ç¥¨åˆ—è¡¨...")
            crawler = StockInfoCrawler(DataRepository())
            result = crawler.create_simplified_stock_list(date_str)
            if result:
                print(f"âœ… {date_str} ç®€åŒ–è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå®Œæˆï¼")
            else:
                print(f"âŒ {date_str} ç®€åŒ–è‚¡ç¥¨åˆ—è¡¨åˆ›å»ºå¤±è´¥ï¼")
        else:
            print("âŒ æ—¥æœŸä¸èƒ½ä¸ºç©º")
    elif choice == '3':
        date_str = input("è¯·è¾“å…¥æ—¥æœŸ (YYYY-MM-DDï¼Œç•™ç©ºä¸ºä»Šå¤©): ").strip()
        if not date_str:
            date_str = None
        print(f"\nğŸ” æŸ¥çœ‹è‚¡ç¥¨åˆ—è¡¨ï¼Œæ—¥æœŸ: {date_str or 'ä»Šå¤©'}")
        crawler = StockInfoCrawler(DataRepository())
        if hasattr(crawler.data_repo, 'csv_storage') and crawler.data_repo.csv_storage:
            stocks = crawler.data_repo.csv_storage.get_stock_list_by_date(date_str or '2025-11-22')
            if stocks:
                print(f"âœ… æ‰¾åˆ° {len(stocks)} æ¡è‚¡ç¥¨è®°å½•")
                print("\nå‰10æ¡è®°å½•:")
                print("-" * 60)
                for i, stock in enumerate(stocks[:10], 1):
                    print(f"{i:2d}. {stock.get('symbol', ''):<10} {stock.get('name', ''):<15} "
                          f"æ›´æ–°æ—¶é—´: {stock.get('crawl_time', '')}")
                if len(stocks) > 10:
                    print(f"... è¿˜æœ‰ {len(stocks) - 10} æ¡è®°å½•")
            else:
                print(f"âŒ æœªæ‰¾åˆ° {date_str or 'ä»Šå¤©'} çš„è‚¡ç¥¨åˆ—è¡¨")
        else:
            print("âŒ å½“å‰ä¸æ”¯æŒæ•°æ®åº“æ¨¡å¼æŸ¥çœ‹")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

def crawl_kline_data():
    """çˆ¬å–Kçº¿æ•°æ®ï¼ˆæŒ‰æ—¥æœŸå­˜å‚¨ï¼‰"""
    print("\nğŸ“Š å¼€å§‹çˆ¬å–Kçº¿æ•°æ®ï¼ˆæŒ‰æ—¥æœŸå­˜å‚¨ï¼‰...")
    crawler = KlineCrawler(DataRepository())
    crawler.crawl_kline_data('after')
    print("âœ… Kçº¿æ•°æ®çˆ¬å–å®Œæˆï¼")

def crawl_financial_data():
    """çˆ¬å–è´¢åŠ¡æ•°æ®ï¼ˆæŒ‰è¯åˆ¸ä»£ç å­˜å‚¨ï¼‰"""
    print("\nğŸ’° å¼€å§‹çˆ¬å–è´¢åŠ¡æ•°æ®ï¼ˆæŒ‰è¯åˆ¸ä»£ç å­˜å‚¨ï¼‰...")
    crawler = FinancialCrawler(DataRepository())
    crawler.crawl_financial_data()
    print("âœ… è´¢åŠ¡æ•°æ®çˆ¬å–å®Œæˆï¼")



def crawl_all_data():
    """çˆ¬å–æ‰€æœ‰æ•°æ®"""
    print("\nğŸ”„ å¼€å§‹çˆ¬å–æ‰€æœ‰æ•°æ®...")
    
    # 1. å…¬å¸ä¿¡æ¯
    print("1/5 çˆ¬å–å…¬å¸ä¿¡æ¯...")
    company_crawler = CompanyInfoCrawler(DataRepository())
    company_crawler.crawl_company_info()
    
    # 2. è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆå®Œæ•´å­—æ®µï¼‰
    print("2/5 è·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆå®Œæ•´å­—æ®µï¼‰...")
    stock_crawler = StockInfoCrawler(DataRepository())
    stock_crawler.crawl_stock_list()
    
    # 3. åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨ï¼ˆç®€åŒ–å­—æ®µï¼‰
    print("3/5 åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨ï¼ˆç®€åŒ–å­—æ®µï¼‰...")
    stock_crawler.create_simplified_stock_list()
    
    # 4. Kçº¿æ•°æ®
    print("4/5 çˆ¬å–Kçº¿æ•°æ®...")
    kline_crawler = KlineCrawler(DataRepository())
    kline_crawler.crawl_kline_data('after')
    
    # 5. è´¢åŠ¡æ•°æ®
    print("5/5 çˆ¬å–è´¢åŠ¡æ•°æ®...")
    financial_crawler = FinancialCrawler(DataRepository())
    financial_crawler.crawl_financial_data()
    
    print("âœ… æ‰€æœ‰æ•°æ®çˆ¬å–å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    # Step 1: æµ‹è¯•è®¤è¯çŠ¶æ€
    print("ğŸ” Step 1: æµ‹è¯•è®¤è¯çŠ¶æ€")
    if not test_authentication():
        print("\nâŒ è®¤è¯çŠ¶æ€å¼‚å¸¸ï¼Œè¯·å…ˆè§£å†³è®¤è¯é—®é¢˜")
        return
    
    # Step 2: æ˜¾ç¤ºèœå•å¹¶æ‰§è¡Œé€‰æ‹©çš„åŠŸèƒ½
    print("\nğŸ“‹ Step 2: é€‰æ‹©è¦çˆ¬å–çš„æ•°æ®ç±»å‹")
    
    while True:
        show_menu()
        choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (0-5): ").strip()
        
        if choice == '0':
            print("ğŸ‘‹ å†è§ï¼")
            break
        elif choice == '1':
            crawl_company_info()
        elif choice == '2':
            get_stock_info()
        elif choice == '3':
            create_stock_list()
        elif choice == '4':
            crawl_kline_data()
        elif choice == '5':
            crawl_financial_data()
        elif choice == '6':
            crawl_all_data()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")

if __name__ == "__main__":
    main()